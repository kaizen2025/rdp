/**
 * Script d'installation et de configuration d'Ollama pour DocuCortex
 * Automatise l'installation d'Ollama et la configuration du mod√®le Llama 3.2 3B
 */

const { exec, spawn } = require('child_process');
const fs = require('fs');
const path = require('path');
const axios = require('axios');

class OllamaInstaller {
    constructor() {
        this.baseUrl = 'http://localhost:11434';
        this.model = 'llama3.2:3b';
        this.isWindows = process.platform === 'win32';
    }

    /**
     * Point d'entr√©e principal
     */
    async install() {
        console.log('üöÄ Installation d\'Ollama pour DocuCortex...\n');

        try {
            // √âtapes d'installation
            await this.checkPrerequisites();
            await this.installOllama();
            await this.startOllama();
            await this.waitForOllama();
            await this.installModel();
            await this.testConnection();
            await this.configureDocuCortex();

            console.log('\n‚úÖ Installation Ollama termin√©e avec succ√®s !');
            console.log('\nüìã Prochaines √©tapes :');
            console.log('   1. DocuCortex d√©marrera automatiquement avec Ollama');
            console.log('   2. Acc√©dez √† l\'interface web DocuCortex');
            console.log('   3. Utilisez les fonctionnalit√©s IA avec Ollama\n');

        } catch (error) {
            console.error('\n‚ùå Erreur lors de l\'installation:', error.message);
            this.showTroubleshooting();
            process.exit(1);
        }
    }

    /**
     * V√©rifie les pr√©requis
     */
    async checkPrerequisites() {
        console.log('üîç V√©rification des pr√©requis...');

        // V√©rifier Node.js
        const nodeVersion = process.version;
        console.log(`   ‚úÖ Node.js ${nodeVersion} d√©tect√©`);

        // V√©rifier npm
        try {
            await this.execCommand('npm --version');
            console.log('   ‚úÖ npm d√©tect√©');
        } catch (error) {
            throw new Error('npm non trouv√©. Veuillez installer Node.js avec npm.');
        }

        // V√©rifier l'acc√®s r√©seau
        try {
            await axios.get('https://registry.npmjs.org/', { timeout: 5000 });
            console.log('   ‚úÖ Acc√®s r√©seau confirm√©');
        } catch (error) {
            console.warn('   ‚ö†Ô∏è Probl√®me de connectivit√© r√©seau d√©tect√©');
        }

        console.log('‚úÖ Pr√©requis valid√©s\n');
    }

    /**
     * Installe Ollama
     */
    async installOllama() {
        console.log('üì¶ Installation d\'Ollama...');

        if (this.isWindows) {
            await this.installOllamaWindows();
        } else {
            await this.installOllamaUnix();
        }

        console.log('‚úÖ Ollama install√©\n');
    }

    /**
     * Installation sur Windows
     */
    async installOllamaWindows() {
        console.log('   ü™ü D√©tection Windows');

        // V√©rifier si Ollama est d√©j√† install√©
        try {
            await this.execCommand('ollama --version');
            console.log('   ‚úÖ Ollama d√©j√† install√©');
            return;
        } catch (error) {
            console.log('   üì• T√©l√©chargement d\'Ollama pour Windows...');
        }

        const downloadUrl = 'https://ollama.ai/download/ollama-amd64.exe';
        const installPath = path.join(process.cwd(), 'ollama.exe');

        try {
            // T√©l√©charger Ollama
            const response = await axios.get(downloadUrl, { responseType: 'stream' });
            const writer = fs.createWriteStream(installPath);
            
            await new Promise((resolve, reject) => {
                response.data.pipe(writer);
                writer.on('finish', resolve);
                writer.on('error', reject);
            });

            console.log('   üì• Ollama t√©l√©charg√©');
            console.log('   ‚ö†Ô∏è Veuillez installer Ollama manuellement depuis le fichier t√©l√©charg√©');
            console.log(`   üìÇ Chemin: ${installPath}`);

        } catch (error) {
            throw new Error(`√âchec du t√©l√©chargement d'Ollama: ${error.message}`);
        }
    }

    /**
     * Installation sur Linux/macOS
     */
    async installOllamaUnix() {
        // V√©rifier si Ollama est d√©j√† install√©
        try {
            await this.execCommand('ollama --version');
            console.log('   ‚úÖ Ollama d√©j√† install√©');
            return;
        } catch (error) {
            console.log('   üì• Installation d\'Ollama...');
        }

        try {
            // Installation via script officiel
            const installCommand = 'curl -fsSL https://ollama.ai/install.sh | sh';
            await this.execCommand(installCommand, { timeout: 300000 }); // 5 minutes timeout
            console.log('   ‚úÖ Script d\'installation ex√©cut√©');

        } catch (error) {
            // Fallback: installation manuelle
            await this.installOllamaManual();
        }
    }

    /**
     * Installation manuelle (fallback)
     */
    async installOllamaManual() {
        console.log('   üîß Installation manuelle d\'Ollama...');

        const commands = [
            // Ubuntu/Debian
            'curl -fsSL https://ollama.ai/download/ollama-linux-amd64 -o ollama',
            'chmod +x ollama',
            'sudo mv ollama /usr/local/bin/',
            
            // ou pour utilisateur local
            'mkdir -p ~/.local/bin',
            'curl -fsSL https://ollama.ai/download/ollama-linux-amd64 -o ~/.local/bin/ollama',
            'chmod +x ~/.local/bin/ollama'
        ];

        for (const command of commands) {
            try {
                await this.execCommand(command);
                console.log(`   ‚úÖ ${command.split(' ').slice(0, 3).join(' ')}...`);
            } catch (error) {
                console.log(`   ‚ö†Ô∏è √âchec: ${command}`);
            }
        }

        // Ajouter au PATH si n√©cessaire
        const shellConfig = this.getShellConfig();
        if (shellConfig && !process.env.PATH.includes('.local/bin')) {
            console.log('   ‚ö†Ô∏è Ajoutez ~/.local/bin √† votre PATH dans .bashrc ou .zshrc');
        }
    }

    /**
     * D√©marre Ollama
     */
    async startOllama() {
        console.log('üöÄ D√©marrage d\'Ollama...');

        if (this.isWindows) {
            console.log('   ü™ü Sur Windows, d√©marrage manuel requis:');
            console.log('      1. Ex√©cutez ollama.exe');
            console.log('      2. Ou utilisez: .\\ollama.exe serve');
            return;
        }

        // V√©rifier si Ollama est d√©j√† en cours d'ex√©cution
        try {
            await axios.get(`${this.baseUrl}/api/tags`, { timeout: 2000 });
            console.log('   ‚úÖ Ollama d√©j√† en cours d\'ex√©cution');
            return;
        } catch (error) {
            console.log('   üîÑ D√©marrage d\'Ollama...');
        }

        try {
            // D√©marrer Ollama en arri√®re-plan
            const ollamaProcess = spawn('ollama', ['serve'], {
                detached: true,
                stdio: 'ignore'
            });

            ollamaProcess.unref();
            console.log('   ‚úÖ Ollama d√©marr√© en arri√®re-plan');

        } catch (error) {
            console.log('   ‚ö†Ô∏è D√©marrage automatique √©chou√©');
            console.log('   üí° D√©marrez Ollama manuellement: ollama serve');
        }

        console.log('   ‚è≥ Attente du d√©marrage d\'Ollama...');
    }

    /**
     * Attend qu'Ollama soit pr√™t
     */
    async waitForOllama() {
        console.log('‚è≥ V√©rification de la disponibilit√© d\'Ollama...');

        const maxAttempts = 30;
        let attempts = 0;

        while (attempts < maxAttempts) {
            try {
                const response = await axios.get(`${this.baseUrl}/api/tags`, { timeout: 2000 });
                if (response.status === 200) {
                    console.log('   ‚úÖ Ollama est pr√™t !');
                    return;
                }
            } catch (error) {
                // Ollama pas encore pr√™t
            }

            attempts++;
            await this.sleep(2000); // Attendre 2 secondes
            console.log(`   ‚è≥ Tentative ${attempts}/${maxAttempts}...`);
        }

        throw new Error('Ollama ne r√©pond pas apr√®s 60 secondes');
    }

    /**
     * Installe le mod√®le Llama 3.2 3B
     */
    async installModel() {
        console.log('ü§ñ Installation du mod√®le Llama 3.2 3B...');

        try {
            // V√©rifier les mod√®les d√©j√† install√©s
            const modelsResponse = await axios.get(`${this.baseUrl}/api/tags`);
            const existingModels = modelsResponse.data.models || [];
            
            const modelExists = existingModels.some(model => 
                model.name.includes('llama3.2') && model.name.includes('3b')
            );

            if (modelExists) {
                console.log('   ‚úÖ Mod√®le Llama 3.2 3B d√©j√† install√©');
                return;
            }

            console.log('   üì• T√©l√©chargement du mod√®le (cela peut prendre quelques minutes)...');

            // T√©l√©charger le mod√®le
            const pullResponse = await axios.post(`${this.baseUrl}/api/pull`, {
                name: this.model
            }, { timeout: 300000 }); // 5 minutes timeout

            if (pullResponse.status === 200) {
                console.log('   ‚úÖ Mod√®le Llama 3.2 3B install√© avec succ√®s');
            }

        } catch (error) {
            console.log('   ‚ùå Erreur lors de l\'installation du mod√®le:');
            console.log(`      ${error.message}`);
            console.log('   üí° Vous pouvez l\'installer plus tard avec: ollama pull llama3.2:3b');
        }
    }

    /**
     * Teste la connexion
     */
    async testConnection() {
        console.log('üß™ Test de connexion Ollama...');

        try {
            // Test 1: V√©rifier les mod√®les
            const modelsResponse = await axios.get(`${this.baseUrl}/api/tags`);
            const models = modelsResponse.data.models || [];
            console.log(`   ‚úÖ ${models.length} mod√®le(s) disponible(s)`);

            // Test 2: Test simple de g√©n√©ration
            const generateResponse = await axios.post(`${this.baseUrl}/api/generate`, {
                model: this.model,
                prompt: 'Hello',
                stream: false
            }, { timeout: 10000 });

            if (generateResponse.data && generateResponse.data.response) {
                console.log('   ‚úÖ Test de g√©n√©ration r√©ussi');
                console.log(`   üìù R√©ponse: "${generateResponse.data.response.trim()}"`);
            }

            console.log('‚úÖ Connexion Ollama valid√©e\n');

        } catch (error) {
            console.log(`   ‚ùå Test √©chou√©: ${error.message}`);
            throw new Error('Impossible de se connecter √† Ollama');
        }
    }

    /**
     * Configure DocuCortex pour utiliser Ollama
     */
    async configureDocuCortex() {
        console.log('‚öôÔ∏è Configuration de DocuCortex...');

        // Cr√©er ou mettre √† jour la configuration Ollama
        const configPath = path.join(process.cwd(), 'config', 'ollama.config.json');
        
        const config = {
            enabled: true,
            host: 'http://localhost:11434',
            model: this.model,
            settings: {
                temperature: 0.7,
                top_p: 0.9,
                top_k: 40,
                maxTokens: 512
            },
            installed: true,
            installationDate: new Date().toISOString()
        };

        try {
            // Cr√©er le r√©pertoire config s'il n'existe pas
            const configDir = path.dirname(configPath);
            if (!fs.existsSync(configDir)) {
                fs.mkdirSync(configDir, { recursive: true });
            }

            fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
            console.log('   ‚úÖ Configuration Ollama cr√©√©e');
            console.log(`   üìÇ Fichier: ${configPath}`);

        } catch (error) {
            console.log(`   ‚ö†Ô∏è Impossible de cr√©er la configuration: ${error.message}`);
        }

        console.log('‚úÖ DocuCortex configur√© pour Ollama\n');
    }

    /**
     * Affiche les conseils de d√©pannage
     */
    showTroubleshooting() {
        console.log('\nüîß Conseils de d√©pannage:\n');
        
        console.log('1. V√©rifiez qu\'Ollama est install√©:');
        console.log('   ollama --version');
        console.log('');
        
        console.log('2. D√©marrez Ollama:');
        console.log('   ollama serve');
        console.log('');
        
        console.log('3. Installez le mod√®le:');
        console.log('   ollama pull llama3.2:3b');
        console.log('');
        
        console.log('4. Testez Ollama:');
        console.log('   curl http://localhost:11434/api/tags');
        console.log('');
        
        console.log('5. Red√©marrez DocuCortex apr√®s installation');
        console.log('');
    }

    // ==================== M√âTHODES UTILITAIRES ====================

    /**
     * Ex√©cute une commande shell
     */
    execCommand(command, options = {}) {
        return new Promise((resolve, reject) => {
            exec(command, options, (error, stdout, stderr) => {
                if (error) {
                    reject(error);
                } else {
                    resolve(stdout.trim());
                }
            });
        });
    }

    /**
     * Attend pendant un certain temps
     */
    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    /**
     * D√©tecte le shell de configuration
     */
    getShellConfig() {
        const shell = process.env.SHELL || '';
        if (shell.includes('zsh')) return '.zshrc';
        if (shell.includes('bash')) return '.bashrc';
        return null;
    }
}

// Point d'entr√©e
if (require.main === module) {
    const installer = new OllamaInstaller();
    installer.install().catch(error => {
        console.error('Erreur fatale:', error.message);
        process.exit(1);
    });
}

module.exports = OllamaInstaller;